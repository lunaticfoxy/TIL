#### 제목: Exploring Randomly Wired Neural Networks For Image Recognition

#### 주소: https://arxiv.org/abs/1904.01569

#### 개요
- 네트워크 구조를 자동 생성하자
- 이미지 인식 분야에서 활용
- 네트워크 구조를 자동 생성하자

#### 기존 연구
- Stochastic Network Generator
  - 완전히 랜덤하게 네트워크를 제너레이팅 하는 모든 방법론
- ResNet, DensNet
  - 웨이트를 순차적으로 연결하지 않고 건너 뛸 수 있는 경로를 제공해줌
  - 경로는 사용자가 지정
- NASNet
  - 모델의 레이어가 모두 연결되어있고 이중 최적의 경로를 찾는 최적화 문제로 판단
  - 건너뛸 수 있는 경로 자체를 RNN을 통해 학습할 수 있게 함
  - 레이어의 큰 방향은 사람이 지정해주고 세부적인 내용만 생성
  - 이걸 좀 더 범용적인 방법으로 구성 할 수 없을까?
  
#### 주제
- NAS와 유사하게 뉴럴넷을 생성해내는 모델을 만들어보자
- 단 좀 더 범요엊ㄱ으로 사용될 수 있도록 해보자

#### 내용
- 랜덤하게 그래프를 생성하자
  - 이 그래프는 뉴럴넷을 위한게 아니라 그냥 정말 랜덤한 그래프이다
  - 이후에 이 그래프 구조를 활용해서 모델을 만들자
- Edge Operation
  - 엣지는 데이터의 흐름으로 이루어진다
- Node Operation
  - 노드의 입려값은 노드로 들어오는 값의 Weighted Sum이다
    - 단 Weight는 [0,1] 범위에서 움직인다
  - 내부에선 1x1 convolution이 일어난다
- 입력 채널과 출력 채널은 항상 동일하다
- 입출력 노드
  - extra input node, output node를 만들어서 붙인다
    - 입력과 출력을 하나로 제한
  - 출력 노드는 단순 평균
  - 단계를 나눠서 단계마다 입력, 출력 구성
    - 단계별 출력은 conlution
    - 단계가 지날때마다 채널수를 2배, convoltion size를 반으로 변화
      - 연산량은 유사하고 정보는 점점 집약되도록
- 관련 네트워크 연구
  - 에르뒤시: (내용 추가 필요)
  - 바라바시 알버츠: 랜덤하게 네트워크가 생성될때 허브를 기준으로 발생할 가능성이 높다
  - Small World
    - 네트워크를 몇다리 건너면 모든 노드가 연결되게 된다
    - 인접한 노드들끼리 연결 후 몇몇 엣지를 건너뛰게 해서 생성될 수 있음
- 생성된 네트워크
  - 무방향 그래프를 만들되 작은 인덱스가 큰 인덱스를 향하도록 하여 사이클이 생기지 않고 일방향으로 표시될 수 있게 함
  - 다음 방법으로 기존 네트워크 연구를 반영한 것을 모델을 한종류씩 생성
    - 에르뒤시를 반영하여 네트워크의 인덱스를 랜덤하게 생성
    - 바라바시의 연구를 인용하여 초기 M개 노드가 허브가 되도록
    - Small World 연구를 이용하여 엣지를 조정
  - 이 결과로 

#### 실험
- 학습은 연산량이 크지 않게 구성
- 노드 수 32, 채널수 79
- vudrbswjrdmfhsms
-
