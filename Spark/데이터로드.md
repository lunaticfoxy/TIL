### 데이터 로드와 관련된 내용을 정리하기 위한 문서

#### filter 연산
- spark의 filter 연산 (=where) 은 데이터의 로드 이후 이루어진다
  - 즉, select 후 filter 연산을 걸게되면 모든 데이터를 로드한 뒤에 연산된다
    - 엄청난 메모리의 낭비
  - 경험상 파티션 조건은 패스되는듯 함
- 따라서 데이터가 크고 조건이 간단할경우 sql문 자체에 where 문으로 조건을 넣는것을 권장한다


#### json 파일 읽기
- spark.read.json(path) 형태로 읽으면 자동으로 DataFrame 으로 만들어줌
- 단 이때 내부에 Row로 저장되므로 문제가 안생기는것이지 각 데이터를 정확히 어떤 타입으로 읽어올지는 다른 문제


#### 이슈 해결
- java.lang.IllegalArgumentException: Field "field_name" does not exist. 에러
  - 현상
    - 분명 있는 필드명을 단순 로드만 했는데 필드명이 없다고 나타나는 케이스
    - Spark sql, 데이터 프레임, rdd 로드 모두 동일한 문제 발생
    - 컬럼 정보 / 스키마 확인시에는 문제 발생하지 않음
  - 원인
    - ORC로 저장된 Hive 테이블을 로드하는중에 Hive에 저장된 메타 정보를 사용
    - 이때 메타 정보를 로드하는 부분에 버그가 있어 생기는 문제
  - 해결 방법
    - spark.sql.hive.convertMetastoreOrc=false 설정을 주어 Hive 메타 정보를 사용하지 않도록 설정
    - Spark 버전을 2.4 이상, Hive 버전을 2.X 이상으로 업데이트
