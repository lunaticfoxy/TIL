### 데이터 로드와 관련된 내용을 정리하기 위한 문서

#### filter 연산
- spark의 filter 연산 (=where) 은 데이터의 로드 이후 이루어진다
  - 즉, select 후 filter 연산을 걸게되면 모든 데이터를 로드한 뒤에 연산된다
    - 엄청난 메모리의 낭비
  - 경험상 파티션 조건은 패스되는듯 함
- 따라서 데이터가 크고 조건이 간단할경우 sql문 자체에 where 문으로 조건을 넣는것을 권장한다


#### json 파일 읽기
- spark.read.json(path) 형태로 읽으면 자동으로 DataFrame 으로 만들어줌
- 단 이때 내부에 Row로 저장되므로 문제가 안생기는것이지 각 데이터를 정확히 어떤 타입으로 읽어올지는 다른 문제
