### 자주 사용되는 피쳐들을 생성하는 방법 정리 예정

#### TF-IDF
```scala
  val allcommentsDf = spark.sql("select * from table")    // 데이터 로드

  val tokenizer = new Tokenizer().setInputCol("content").setOutputCol("words")
  val wordsData = tokenizer.transform(allcommentsDf)      // 토큰단위로 분리 (입력: content, 출력: words)

  val hashingTF = new HashingTF().setInputCol("words").setOutputCol("rawFeatures") //.setNumFeatures(20)
  val featurizedData = hashingTF.transform(wordsData)     // TF 벡터 생성 (입력: words, 출력: rawFeatures)

  val idf = new IDF().setInputCol("rawFeatures").setOutputCol("features")
  val idfModel = idf.fit(featurizedData)                  // IDF 계산
  val rescaledData = idfModel.transform(featurizedData)   // TF벡터를 TF-IDF 벡터로 변환 (입력: rawFeatures, 출력: features)
  
  val features = rescaledData.select("id", "content", "features")
  features.write.mode("overwrite").saveAsTable("res_table") // 테이블에 결과 저장 (features는 Sparse Vector 형태로 저장됨)
```

#### Onehot vector
```scala
val df = spark.createDataFrame(
Seq((0, "Jason", "Germany"),
(1, "David", "France"),
(2, "Martin", "Spain"),
(3, "Jason", "USA"),
(4, "Daiel", "UK"),
(5, "Moahmed", "Bangladesh"),
(6, "David", "Ireland"),
(7, "Jason", "Netherlands"))).toDF("id", "name", "address")


import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.feature.OneHotEncoder


val indexer = new StringIndexer()
                 .setInputCol("name")
                 .setOutputCol("categoryIndex")
                 .fit(df)

val indexed = indexer.transform(df)

val encoder = new OneHotEncoder()
                 .setInputCol("categoryIndex")
                 .setOutputCol("categoryVec")

val encoded = encoder.transform(indexed)
encoded.show()





```
